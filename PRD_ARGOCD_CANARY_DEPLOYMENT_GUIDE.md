# Product Requirements Document: PODINFO: Argocd Canary Deployment Guide

---

## Document Information
**Project:** podinfo
**Document:** ARGOCD_CANARY_DEPLOYMENT_GUIDE
**Version:** 1.0.0
**Date:** 2025-10-13
**Status:** READY FOR TASK-MASTER PARSING

---

## 1. EXECUTIVE SUMMARY

### 1.1 Overview
This PRD captures the requirements and implementation details for PODINFO: Argocd Canary Deployment Guide.

### 1.2 Purpose
This document provides a structured specification that can be parsed by task-master to generate actionable tasks.

### 1.3 Scope
The scope includes all requirements, features, and implementation details from the original documentation.

---

## 2. REQUIREMENTS

### 2.1 Functional Requirements
**Priority:** HIGH

**REQ-001:** automatically detect and sync


## 3. TASKS

The following tasks have been identified for implementation:

**TASK_001** [HIGH]: [Overview](#overview)

**TASK_002** [HIGH]: [Architecture](#architecture)

**TASK_003** [HIGH]: [Prerequisites](#prerequisites)

**TASK_004** [HIGH]: [Quick Start](#quick-start)

**TASK_005** [HIGH]: [Deployment Steps](#deployment-steps)

**TASK_006** [HIGH]: [Canary Strategy](#canary-strategy)

**TASK_007** [HIGH]: [Monitoring & Observability](#monitoring--observability)

**TASK_008** [HIGH]: [Operations Guide](#operations-guide)

**TASK_009** [HIGH]: [Troubleshooting](#troubleshooting)

**TASK_010** [HIGH]: [References](#references)

**TASK_011** [MEDIUM]: **Kubernetes cluster** (v1.24+)

**TASK_012** [MEDIUM]: **kubectl** CLI installed

**TASK_013** [MEDIUM]: **Helm** (v3+) for package management

**TASK_014** [MEDIUM]: **Argo Rollouts kubectl plugin**

**TASK_015** [MEDIUM]: **jq** for JSON processing

**TASK_016** [MEDIUM]: **curl** for API testing

**TASK_017** [MEDIUM]: At least 3 worker nodes for HA

**TASK_018** [MEDIUM]: NGINX Ingress Controller installed

**TASK_019** [MEDIUM]: Prometheus Operator (for metrics)

**TASK_020** [MEDIUM]: cert-manager (for TLS certificates)

**TASK_021** [HIGH]: Install ArgoCD

**TASK_022** [HIGH]: Install Argo Rollouts

**TASK_023** [HIGH]: Deploy podinfo with canary strategy

**TASK_024** [HIGH]: Configure monitoring

**TASK_025** [HIGH]: Display access credentials

**TASK_026** [MEDIUM]: **Traffic**: 10% to canary

**TASK_027** [MEDIUM]: **Duration**: 2 minutes

**TASK_028** [MEDIUM]: **Analysis**: Success rate, latency

**TASK_029** [MEDIUM]: **Action**: Auto-promote or rollback

**TASK_030** [MEDIUM]: **Traffic**: 30% to canary

**TASK_031** [MEDIUM]: **Duration**: 5 minutes

**TASK_032** [MEDIUM]: **Analysis**: Success rate, latency, error rate

**TASK_033** [MEDIUM]: **Action**: Auto-promote or rollback

**TASK_034** [MEDIUM]: **Traffic**: 50% to canary

**TASK_035** [MEDIUM]: **Duration**: Manual approval required

**TASK_036** [MEDIUM]: **Analysis**: All metrics

**TASK_037** [MEDIUM]: **Action**: Manual promotion

**TASK_038** [MEDIUM]: **Traffic**: 75% to canary

**TASK_039** [MEDIUM]: **Duration**: 5 minutes

**TASK_040** [MEDIUM]: **Analysis**: Success rate, latency

**TASK_041** [MEDIUM]: **Action**: Auto-promote or rollback

**TASK_042** [MEDIUM]: **Traffic**: 100% to canary

**TASK_043** [MEDIUM]: **Duration**: 1 minute stabilization

**TASK_044** [MEDIUM]: **Action**: Complete

**TASK_045** [MEDIUM]: **Threshold**: â‰¥ 95%

**TASK_046** [MEDIUM]: **Measurement**: HTTP 2xx responses / total requests

**TASK_047** [MEDIUM]: **Interval**: 30 seconds

**TASK_048** [MEDIUM]: **Failure Limit**: 3 consecutive failures

**TASK_049** [MEDIUM]: **Threshold**: â‰¤ 500ms

**TASK_050** [MEDIUM]: **Measurement**: 95th percentile response time

**TASK_051** [MEDIUM]: **Interval**: 30 seconds

**TASK_052** [MEDIUM]: **Failure Limit**: 3 consecutive failures

**TASK_053** [MEDIUM]: **Threshold**: â‰¤ 5%

**TASK_054** [MEDIUM]: **Measurement**: HTTP 5xx responses / total requests

**TASK_055** [MEDIUM]: **Interval**: 30 seconds

**TASK_056** [MEDIUM]: **Failure Limit**: 3 consecutive failures

**TASK_057** [MEDIUM]: Request Rate (Stable vs Canary)

**TASK_058** [MEDIUM]: Success Rate Gauges

**TASK_059** [MEDIUM]: Latency Percentiles

**TASK_060** [MEDIUM]: Current Canary Weight

**TASK_061** [MEDIUM]: Rollout Status

**TASK_062** [MEDIUM]: Replica Counts

**TASK_063** [MEDIUM]: Analysis Run Status

**TASK_064** [MEDIUM]: Check if Prometheus is accessible

**TASK_065** [MEDIUM]: Verify ServiceMonitor configuration

**TASK_066** [MEDIUM]: Check analysis template queries

**TASK_067** [MEDIUM]: Review pod logs for errors

**TASK_068** [MEDIUM]: Verify Prometheus metrics are being collected

**TASK_069** [MEDIUM]: Check metric query syntax

**TASK_070** [MEDIUM]: Adjust analysis thresholds if too strict

**TASK_071** [MEDIUM]: Review application logs for actual errors

**TASK_072** [MEDIUM]: Verify NGINX Ingress Controller is installed

**TASK_073** [MEDIUM]: Check canary-weight annotation on ingress

**TASK_074** [MEDIUM]: Ensure Argo Rollouts has permissions to update ingress

**TASK_075** [MEDIUM]: Verify services are correctly labeled

**TASK_076** [MEDIUM]: Verify analysis templates are correctly referenced

**TASK_077** [MEDIUM]: Check failureLimit settings

**TASK_078** [MEDIUM]: Ensure Prometheus queries return valid data

**TASK_079** [MEDIUM]: Review analysis template success conditions

**TASK_080** [MEDIUM]: name: success-rate

**TASK_081** [MEDIUM]: name: custom-business-metric

**TASK_082** [MEDIUM]: **RBAC**: Limit who can promote/abort rollouts

**TASK_083** [MEDIUM]: **Network Policies**: Restrict pod-to-pod communication

**TASK_084** [MEDIUM]: **Image Scanning**: Scan images before deployment

**TASK_085** [MEDIUM]: **Secrets Management**: Use external secrets operator

**TASK_086** [MEDIUM]: **TLS**: Enable TLS for all ingress traffic

**TASK_087** [MEDIUM]: **Replica Count**: Adjust based on traffic (minimum 6 recommended)

**TASK_088** [MEDIUM]: **HPA**: Configured to scale 3-10 replicas

**TASK_089** [MEDIUM]: **Resource Limits**: CPU: 500m, Memory: 512Mi

**TASK_090** [MEDIUM]: **Analysis Intervals**: Balance between speed and accuracy

**TASK_091** [MEDIUM]: [Argo Rollouts Documentation](https://argoproj.github.io/argo-rollouts/)

**TASK_092** [MEDIUM]: [ArgoCD Documentation](https://argo-cd.readthedocs.io/)

**TASK_093** [MEDIUM]: [Canary Deployment Best Practices](https://argoproj.github.io/argo-rollouts/features/canary/)

**TASK_094** [MEDIUM]: [Podinfo GitHub](https://github.com/stefanprodan/podinfo)

**TASK_095** [HIGH]: Check troubleshooting section above

**TASK_096** [HIGH]: Review Argo Rollouts documentation

**TASK_097** [HIGH]: Check application logs and events

**TASK_098** [HIGH]: Open an issue in the project repository


## 4. DETAILED SPECIFICATIONS

### 4.1 Original Content

The following sections contain the original documentation:


#### Argocd Canary Deployment Guide For Podinfo

# ArgoCD Canary Deployment Guide for Podinfo


####  Table Of Contents

## ğŸ“‹ Table of Contents

1. [Overview](#overview)
2. [Architecture](#architecture)
3. [Prerequisites](#prerequisites)
4. [Quick Start](#quick-start)
5. [Deployment Steps](#deployment-steps)
6. [Canary Strategy](#canary-strategy)
7. [Monitoring & Observability](#monitoring--observability)
8. [Operations Guide](#operations-guide)
9. [Troubleshooting](#troubleshooting)
10. [References](#references)


#### Overview

## Overview

This guide provides complete instructions for implementing progressive canary deployments for the podinfo application using **ArgoCD** and **Argo Rollouts**.


#### What You Ll Get

### What You'll Get

âœ… **Zero-downtime canary deployments** with 5-stage traffic progression (10% â†’ 30% â†’ 50% â†’ 75% â†’ 100%)
âœ… **Automated analysis** using Prometheus metrics (success rate, latency, error rate)
âœ… **Automatic rollback** on metric degradation
âœ… **Manual approval gates** for production safety
âœ… **Complete observability** with Grafana dashboards
âœ… **GitOps workflow** with ArgoCD


#### Architecture

## Architecture


#### Component Overview

### Component Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      User Traffic                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                â”‚   Ingress   â”‚
                â”‚  (NGINX)    â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Stable Service â”‚    â”‚Canary Serviceâ”‚
    â”‚    (100-x%)    â”‚    â”‚     (x%)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Stable Pods    â”‚    â”‚ Canary Pods  â”‚
    â”‚   (v1.0)       â”‚    â”‚   (v1.1)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                â”‚ Prometheus  â”‚
                â”‚  (Metrics)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                â”‚ Analysis    â”‚
                â”‚  Templates  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


#### Canary Progression

### Canary Progression

```
Stage 1:  10% â”€â”€â–¶  2min + Analysis  â”€â”€â–¶  Next or Rollback
Stage 2:  30% â”€â”€â–¶  5min + Analysis  â”€â”€â–¶  Next or Rollback
Stage 3:  50% â”€â”€â–¶ Manual Approval   â”€â”€â–¶  Next or Rollback
Stage 4:  75% â”€â”€â–¶  5min + Analysis  â”€â”€â–¶  Next or Rollback
Stage 5: 100% â”€â”€â–¶  Complete
```


#### Prerequisites

## Prerequisites


#### Required Tools

### Required Tools

- **Kubernetes cluster** (v1.24+)
- **kubectl** CLI installed
- **Helm** (v3+) for package management
- **Argo Rollouts kubectl plugin**


#### Optional Tools

### Optional Tools

- **jq** for JSON processing
- **curl** for API testing


#### Cluster Requirements

### Cluster Requirements

- At least 3 worker nodes for HA
- NGINX Ingress Controller installed
- Prometheus Operator (for metrics)
- cert-manager (for TLS certificates)


#### Quick Start

## Quick Start


#### One Line Installation

### One-Line Installation

```bash
cd k8s-cluster/scripts
./deploy-argocd-canary.sh
```

This script will:
1. Install ArgoCD
2. Install Argo Rollouts
3. Deploy podinfo with canary strategy
4. Configure monitoring
5. Display access credentials


#### Manual Installation

### Manual Installation

Follow the [Deployment Steps](#deployment-steps) section below.


#### Deployment Steps

## Deployment Steps


#### Step 1 Install Argocd

### Step 1: Install ArgoCD

```bash

#### Create Namespace

# Create namespace
kubectl create namespace argo-rollouts


#### Install Argocd

# Install ArgoCD
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml


#### Wait For Pods To Be Ready

# Wait for pods to be ready
kubectl wait --for=condition=available --timeout=600s deployment/argocd-server -n argocd


#### Get Admin Password

# Get admin password
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d


#### Access Argocd Ui

# Access ArgoCD UI
kubectl port-forward svc/argocd-server -n argocd 8080:443

#### Visit Https Localhost 8080

# Visit: https://localhost:8080
```


#### Step 2 Install Argo Rollouts

### Step 2: Install Argo Rollouts

```bash

#### Install Argo Rollouts

# Install Argo Rollouts
kubectl apply -n argo-rollouts -f https://github.com/argoproj/argo-rollouts/releases/latest/download/install.yaml


#### Install Kubectl Plugin Linux 

# Install kubectl plugin (Linux)
curl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-linux-amd64
chmod +x kubectl-argo-rollouts-linux-amd64
sudo mv kubectl-argo-rollouts-linux-amd64 /usr/local/bin/kubectl-argo-rollouts


#### Verify Installation

# Verify installation
kubectl argo rollouts version
```


#### Step 3 Deploy Podinfo Rollout

### Step 3: Deploy Podinfo Rollout

```bash

#### Apply All Manifests

# Apply all manifests
kubectl apply -f k8s-cluster/manifests/14-cicd/podinfo-rollout.yaml
kubectl apply -f k8s-cluster/manifests/14-cicd/podinfo-analysis-templates.yaml
kubectl apply -f k8s-cluster/manifests/14-cicd/podinfo-monitoring.yaml
kubectl apply -f k8s-cluster/manifests/14-cicd/podinfo-ingress.yaml


#### Verify Deployment

# Verify deployment
kubectl get rollout -n podinfo
kubectl argo rollouts status podinfo -n podinfo
```


#### Step 4 Configure Argocd Application

### Step 4: Configure ArgoCD Application

```bash

#### Apply Argocd Application

# Apply ArgoCD Application
kubectl apply -f k8s-cluster/manifests/14-cicd/podinfo-argocd-application.yaml


#### Sync Application

# Sync application
argocd app sync podinfo --force
```


#### Step 5 Setup Monitoring

### Step 5: Setup Monitoring

```bash

#### Apply Servicemonitors

# Apply ServiceMonitors
kubectl apply -f k8s-cluster/manifests/14-cicd/podinfo-monitoring.yaml


#### Import Grafana Dashboard

# Import Grafana dashboard
kubectl apply -f k8s-cluster/manifests/14-cicd/podinfo-grafana-dashboard.yaml
```


#### Canary Strategy

## Canary Strategy


#### Stage Configuration

### Stage Configuration

Our canary strategy implements a 5-stage progressive delivery:


#### Stage 1 Initial Canary 10 

#### Stage 1: Initial Canary (10%)
- **Traffic**: 10% to canary
- **Duration**: 2 minutes
- **Analysis**: Success rate, latency
- **Action**: Auto-promote or rollback


#### Stage 2 Expanded Test 30 

#### Stage 2: Expanded Test (30%)
- **Traffic**: 30% to canary
- **Duration**: 5 minutes
- **Analysis**: Success rate, latency, error rate
- **Action**: Auto-promote or rollback


#### Stage 3 Half Traffic 50 

#### Stage 3: Half Traffic (50%)
- **Traffic**: 50% to canary
- **Duration**: Manual approval required
- **Analysis**: All metrics
- **Action**: Manual promotion


#### Stage 4 Majority Traffic 75 

#### Stage 4: Majority Traffic (75%)
- **Traffic**: 75% to canary
- **Duration**: 5 minutes
- **Analysis**: Success rate, latency
- **Action**: Auto-promote or rollback


#### Stage 5 Full Rollout 100 

#### Stage 5: Full Rollout (100%)
- **Traffic**: 100% to canary
- **Duration**: 1 minute stabilization
- **Action**: Complete


#### Analysis Metrics

### Analysis Metrics


#### Success Rate

#### Success Rate
- **Threshold**: â‰¥ 95%
- **Measurement**: HTTP 2xx responses / total requests
- **Interval**: 30 seconds
- **Failure Limit**: 3 consecutive failures


#### Latency P95 

#### Latency (P95)
- **Threshold**: â‰¤ 500ms
- **Measurement**: 95th percentile response time
- **Interval**: 30 seconds
- **Failure Limit**: 3 consecutive failures


#### Error Rate

#### Error Rate
- **Threshold**: â‰¤ 5%
- **Measurement**: HTTP 5xx responses / total requests
- **Interval**: 30 seconds
- **Failure Limit**: 3 consecutive failures


#### Monitoring Observability

## Monitoring & Observability


#### Grafana Dashboard

### Grafana Dashboard

Access the pre-configured Grafana dashboard:

```bash
kubectl port-forward -n monitoring svc/grafana 3000:80

#### Visit Http Localhost 3000

# Visit: http://localhost:3000

#### Dashboard Podinfo Canary Deployment 

# Dashboard: "Podinfo Canary Deployment"
```

**Dashboard Panels:**
- Request Rate (Stable vs Canary)
- Success Rate Gauges
- Latency Percentiles
- Error Rate
- Current Canary Weight
- Rollout Status
- Replica Counts
- Analysis Run Status


#### Prometheus Queries

### Prometheus Queries

**Success Rate:**
```promql
sum(rate(http_request_duration_seconds_count{job="podinfo-canary",status=~"2.."}[5m]))
/
sum(rate(http_request_duration_seconds_count{job="podinfo-canary"}[5m]))
```

**P95 Latency:**
```promql
histogram_quantile(0.95,
  sum(rate(http_request_duration_seconds_bucket{job="podinfo-canary"}[5m])) by (le)
)
```

**Error Rate:**
```promql
sum(rate(http_request_duration_seconds_count{job="podinfo-canary",status=~"5.."}[5m]))
/
sum(rate(http_request_duration_seconds_count{job="podinfo-canary"}[5m]))
```


#### Argo Rollouts Dashboard

### Argo Rollouts Dashboard

```bash
kubectl argo rollouts dashboard -n podinfo

#### Visit Http Localhost 3100

# Visit: http://localhost:3100
```


#### Operations Guide

## Operations Guide


#### Trigger A Canary Deployment

### Trigger a Canary Deployment


#### Method 1 Update Image Via Cli

#### Method 1: Update Image via CLI
```bash
./k8s-cluster/scripts/manage-rollout.sh update-image ghcr.io/stefanprodan/podinfo:6.9.3
```


#### Method 2 Update Via Kubectl

#### Method 2: Update via kubectl
```bash
kubectl argo rollouts set image podinfo podinfo=ghcr.io/stefanprodan/podinfo:6.9.3 -n podinfo
```


#### Method 3 Update Via Argocd Gitops 

#### Method 3: Update via ArgoCD (GitOps)
```bash

#### Update Image Tag In Git Repository

# Update image tag in Git repository
git add kustomize/
git commit -m "Update podinfo to 6.9.3"
git push


#### Argocd Will Automatically Detect And Sync

# ArgoCD will automatically detect and sync
```


#### Monitor Rollout Progress

### Monitor Rollout Progress

```bash

#### Watch Live Status

# Watch live status
./k8s-cluster/scripts/manage-rollout.sh watch


#### Get Current Status

# Get current status
./k8s-cluster/scripts/manage-rollout.sh status


#### View Analysis Runs

# View analysis runs
kubectl get analysisrun -n podinfo -o yaml


#### Manual Promotion

### Manual Promotion

```bash

#### Promote To Next Stage

# Promote to next stage
./k8s-cluster/scripts/manage-rollout.sh promote


#### Promote Fully Skip All Analysis 

# Promote fully (skip all analysis)
./k8s-cluster/scripts/manage-rollout.sh promote-full
```


#### Abort And Rollback

### Abort and Rollback

```bash

#### Abort Current Rollout

# Abort current rollout
./k8s-cluster/scripts/manage-rollout.sh abort


#### Rollback To Specific Revision

# Rollback to specific revision
./k8s-cluster/scripts/manage-rollout.sh history
./k8s-cluster/scripts/manage-rollout.sh rollback <revision-number>
```


#### Test Canary With Header

### Test Canary with Header

```bash

#### Test Stable Version

# Test stable version
curl http://podinfo.example.com


#### Test Canary Version

# Test canary version
curl -H "X-Canary: true" http://podinfo.example.com


#### Automated Test

# Automated test
./k8s-cluster/scripts/manage-rollout.sh test-canary http://podinfo.example.com
```


#### Pause And Resume

### Pause and Resume

```bash

#### Pause Rollout

# Pause rollout
./k8s-cluster/scripts/manage-rollout.sh pause


#### Resume Rollout

# Resume rollout
./k8s-cluster/scripts/manage-rollout.sh resume
```


#### Troubleshooting

## Troubleshooting


#### Common Issues

### Common Issues


#### 1 Rollout Stuck In Progressing

#### 1. Rollout Stuck in Progressing

**Symptoms**: Rollout doesn't progress beyond a stage

**Diagnosis**:
```bash
kubectl describe rollout podinfo -n podinfo
kubectl get analysisrun -n podinfo
kubectl describe analysisrun <latest-run> -n podinfo
```

**Solutions**:
- Check if Prometheus is accessible
- Verify ServiceMonitor configuration
- Check analysis template queries
- Review pod logs for errors


#### 2 Analysis Failing

#### 2. Analysis Failing

**Symptoms**: Analysis runs show "Failed" status

**Diagnosis**:
```bash
kubectl logs -n podinfo deployment/podinfo-canary
kubectl get analysisrun -n podinfo -o yaml
```

**Solutions**:
- Verify Prometheus metrics are being collected
- Check metric query syntax
- Adjust analysis thresholds if too strict
- Review application logs for actual errors


#### 3 Traffic Not Splitting

#### 3. Traffic Not Splitting

**Symptoms**: All traffic goes to stable or canary

**Diagnosis**:
```bash
kubectl get ingress -n podinfo
kubectl describe ingress podinfo-canary -n podinfo
```

**Solutions**:
- Verify NGINX Ingress Controller is installed
- Check canary-weight annotation on ingress
- Ensure Argo Rollouts has permissions to update ingress
- Verify services are correctly labeled


#### 4 Automatic Rollback Not Working

#### 4. Automatic Rollback Not Working

**Symptoms**: Canary continues despite bad metrics

**Diagnosis**:
```bash
kubectl get analysistemplate -n podinfo
kubectl describe analysisrun <latest-run> -n podinfo
```

**Solutions**:
- Verify analysis templates are correctly referenced
- Check failureLimit settings
- Ensure Prometheus queries return valid data
- Review analysis template success conditions


#### Debug Commands

### Debug Commands

```bash

#### Check All Resources

# Check all resources
kubectl get all -n podinfo


#### View Rollout Events

# View rollout events
kubectl get events -n podinfo --sort-by='.lastTimestamp'


#### Check Argo Rollouts Controller Logs

# Check Argo Rollouts controller logs
kubectl logs -n argo-rollouts deployment/argo-rollouts


#### Test Prometheus Connectivity

# Test Prometheus connectivity
kubectl run -it --rm debug --image=curlimages/curl --restart=Never -- \
  curl http://prometheus.monitoring.svc:9090/api/v1/query?query=up
```


#### Advanced Configuration

## Advanced Configuration


#### Custom Analysis Intervals

### Custom Analysis Intervals

Edit `podinfo-analysis-templates.yaml` to adjust:

```yaml
metrics:
- name: success-rate
  interval: 60s  # Change from 30s to 60s
  successCondition: result[0] >= 0.95
  failureLimit: 5  # Change from 3 to 5
```


#### Add Custom Metrics

### Add Custom Metrics

Create new AnalysisTemplate:

```yaml
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: podinfo-custom-metric
  namespace: podinfo
spec:
  metrics:
  - name: custom-business-metric
    interval: 30s
    successCondition: result[0] >= 100
    provider:
      prometheus:
        address: http://prometheus.monitoring.svc:9090
        query: |
          your_custom_metric{service="podinfo"}
```


#### Integrate With Service Mesh Istio 

### Integrate with Service Mesh (Istio)

Replace NGINX ingress with Istio VirtualService (see comments in `podinfo-ingress.yaml`).


#### Security Considerations

## Security Considerations

- **RBAC**: Limit who can promote/abort rollouts
- **Network Policies**: Restrict pod-to-pod communication
- **Image Scanning**: Scan images before deployment
- **Secrets Management**: Use external secrets operator
- **TLS**: Enable TLS for all ingress traffic


#### Performance Tuning

## Performance Tuning

- **Replica Count**: Adjust based on traffic (minimum 6 recommended)
- **HPA**: Configured to scale 3-10 replicas
- **Resource Limits**: CPU: 500m, Memory: 512Mi
- **Analysis Intervals**: Balance between speed and accuracy


#### References

## References

- [Argo Rollouts Documentation](https://argoproj.github.io/argo-rollouts/)
- [ArgoCD Documentation](https://argo-cd.readthedocs.io/)
- [Canary Deployment Best Practices](https://argoproj.github.io/argo-rollouts/features/canary/)
- [Podinfo GitHub](https://github.com/stefanprodan/podinfo)


#### Support

## Support

For issues or questions:
1. Check troubleshooting section above
2. Review Argo Rollouts documentation
3. Check application logs and events
4. Open an issue in the project repository

---

**Implementation Complete!** ğŸ‰

All components of the ArgoCD canary deployment system are now deployed and ready for use.


---

## 5. TECHNICAL REQUIREMENTS

### 5.1 Dependencies
- All dependencies from original documentation apply
- Standard development environment
- Required tools and libraries as specified

### 5.2 Compatibility
- Compatible with existing infrastructure
- Follows project standards and conventions

---

## 6. SUCCESS CRITERIA

### 6.1 Functional Success Criteria
- All identified tasks completed successfully
- All requirements implemented as specified
- All tests passing

### 6.2 Quality Success Criteria
- Code meets quality standards
- Documentation is complete and accurate
- No critical issues remaining

---

## 7. IMPLEMENTATION PLAN

### Phase 1: Preparation
- Review all requirements and tasks
- Set up development environment
- Gather necessary resources

### Phase 2: Implementation
- Execute tasks in priority order
- Follow best practices
- Test incrementally

### Phase 3: Validation
- Run comprehensive tests
- Validate against requirements
- Document completion

---

## 8. TASK-MASTER INTEGRATION

### How to Parse This PRD

```bash
# Parse this PRD with task-master
task-master parse-prd --input="{doc_name}_PRD.md"

# List generated tasks
task-master list

# Start execution
task-master next
```

### Expected Task Generation
Task-master should generate approximately {len(tasks)} tasks from this PRD.

---

## 9. APPENDIX

### 9.1 References
- Original document: {doc_name}.md
- Project: {project_name}

### 9.2 Change History
| Version | Date | Changes |
|---------|------|---------|
| 1.0.0 | {datetime.now().strftime('%Y-%m-%d')} | Initial PRD conversion |

---

*End of PRD*
*Generated by MD-to-PRD Converter*
